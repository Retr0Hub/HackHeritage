{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition Sign-In System
",
    "
",
    "This notebook demonstrates a simple face recognition system for sign-in. It uses your webcam to detect faces and compares them against a dataset of known faces. If a match is found, it can simulate a sign-in.
",
    "
",
    "## Setup
",
    "
",
    "Before running this notebook, you need to install the required libraries. Open your terminal or command prompt and run the following commands:
",
    "
",
    "```bash
",
    "pip install jupyterlab face_recognition opencv-python numpy ipywidgets
",
    "```
",
    "
",
    "## Dataset Preparation
",
    "
",
    "Place your known faces in the `dataset/images` directory. For each person, create a separate folder with their name, and put their images inside that folder. For example:
",
    "
",
    "```
",
    "FaceSignIn/
",
    "├── dataset/
",
    "│   └── images/
",
    "│       ├── John_Doe/
",
    "│       │   ├── john_1.jpg
",
    "│       │   └── john_2.jpg
",
    "│       └── Jane_Smith/
",
    "│           ├── jane_1.jpg
",
    "│           └── jane_2.jpg
",
    "└── face_signin.ipynb
",
    "```
",
    "
",
    "Make sure the images clearly show the person's face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition
",
    "import cv2
",
    "import numpy as np
",
    "import os
",
    "from IPython.display import display, Image
",
    "import ipywidgets as widgets
",
    "from threading import Thread
",
    "import time
",
    "
",
    "# Global variables
",
    "video_capture = None
",
    "known_face_encodings = []
",
    "known_face_names = []
",
    "process_this_frame = True
",
    "signed_in_user = None
",
    "running = False
",
    "
",
    "output_widget = widgets.Output()
",
    "image_widget = widgets.Image(format='jpeg', width=640, height=480)
",
    "sign_in_button = widgets.Button(description="Sign In")
",
    "status_label = widgets.Label(value="Status: Not signed in")
",
    "
",
    "display(image_widget, sign_in_button, status_label, output_widget)
",
    "
",
    "def load_known_faces(dataset_path="dataset/images"):
",
    "    global known_face_encodings, known_face_names
",
    "    known_face_encodings = []
",
    "    known_face_names = []
",
    "
",
    "    with output_widget:
",
    "        print("Loading known faces...")
",
    "        for person_name in os.listdir(dataset_path):
",
    "            person_dir = os.path.join(dataset_path, person_name)
",
    "            if os.path.isdir(person_dir):
",
    "                for image_name in os.listdir(person_dir):
",
    "                    if image_name.endswith((".jpg", ".png", ".jpeg")):
",
    "                        image_path = os.path.join(person_dir, image_name)
",
    "                        try:
",
    "                            image = face_recognition.load_image_file(image_path)
",
    "                            face_encodings = face_recognition.face_encodings(image)
",
    "                            if face_encodings:
",
    "                                known_face_encodings.append(face_encodings[0])
",
    "                                known_face_names.append(person_name)
",
    "                                print(f"Loaded {person_name} from {image_name}")
",
    "                            else:
",
    "                                print(f"No face found in {image_name} for {person_name}")
",
    "                        except Exception as e:
",
    "                            print(f"Error loading {image_path}: {e}")
",
    "        print(f"Loaded {len(known_face_names)} known faces.")
",
    "
",
    "def recognize_faces():
",
    "    global process_this_frame, signed_in_user, running
",
    "    face_locations = []
",
    "    face_encodings = []
",
    "    face_names = []
",
    "
",
    "    while running:
",
    "        ret, frame = video_capture.read()
",
    "        if not ret:
",
    "            with output_widget:
",
    "                print("Failed to grab frame")
",
    "            break
",
    "
",
    "        # Resize frame of video to 1/4 size for faster face recognition processing
",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)
",
    "
",
    "        # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)
",
    "        rgb_small_frame = small_frame[:, :, ::-1]
",
    "
",
    "        if process_this_frame:
",
    "            # Find all the faces and face encodings in the current frame of video
",
    "            face_locations = face_recognition.face_locations(rgb_small_frame)
",
    "            face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)
",
    "
",
    "            face_names = []
",
    "            current_frame_user = None
",
    "            for face_encoding in face_encodings:
",
    "                # See if the face is a match for the known face(s)
",
    "                matches = face_recognition.compare_faces(known_face_encodings, face_encoding)
",
    "                name = "Unknown"
",
    "
",
    "                # # If a match was found in known_face_encodings, just use the first one.
",
    "                # if True in matches:
",
    "                #     first_match_index = matches.index(True)
",
    "                #     name = known_face_names[first_match_index]
",
    "
",
    "                # Or instead, use the known face with the smallest distance to the new face
",
    "                face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)
",
    "                best_match_index = np.argmin(face_distances)
",
    "                if matches[best_match_index]:
",
    "                    name = known_face_names[best_match_index]
",
    "                    current_frame_user = name
",
    "
",
    "                face_names.append(name)
",
    "            
",
    "            if current_frame_user and not signed_in_user:
",
    "                status_label.value = f"Status: Detected {current_frame_user}. Click Sign In."
",
    "            elif not current_frame_user and not signed_in_user:
",
    "                status_label.value = "Status: No known face detected."
",
    "            
",
    "        process_this_frame = not process_this_frame
",
    "
",
    "        # Display the results
",
    "        for (top, right, bottom, left), name in zip(face_locations, face_names):
",
    "            # Scale back up face locations since the frame was scaled to 1/4 size
",
    "            top *= 4
",
    "            right *= 4
",
    "            bottom *= 4
",
    "            left *= 4
",
    "
",
    "            # Draw a box around the face
",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)
",
    "
",
    "            # Draw a label with a name below the face
",
    "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)
",
    "            font = cv2.FONT_HERSHEY_DUPLEX
",
    "            cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)
",
    "
",
    "        # Convert the frame to JPEG format for display in the widget
",
    "        _, jpeg = cv2.imencode('.jpeg', frame)
",
    "        image_widget.value = jpeg.tobytes()
",
    "
",
    "    if video_capture:
",
    "        video_capture.release()
",
    "    with output_widget:
",
    "        print("Video capture stopped.")
",
    "
",
    "def start_recognition():
",
    "    global video_capture, running
",
    "    if not running:
",
    "        load_known_faces()
",
    "        video_capture = cv2.VideoCapture(0) # 0 for default webcam
",
    "        if not video_capture.isOpened():
",
    "            with output_widget:
",
    "                print("Error: Could not open video stream. Check if webcam is available.")
",
    "            return
",
    "        running = True
",
    "        Thread(target=recognize_faces).start()
",
    "        with output_widget:
",
    "            print("Face recognition started.")
",
    "
",
    "def stop_recognition():
",
    "    global running, signed_in_user
",
    "    running = False
",
    "    signed_in_user = None
",
    "    status_label.value = "Status: Not signed in"
",
    "    with output_widget:
",
    "        print("Face recognition stopped.")
",
    "
",
    "def on_sign_in_button_clicked(b):
",
    "    global signed_in_user
",
    "    if running and not signed_in_user:
",
    "        # Get the current detected face name
",
    "        # This is a simplified approach; in a real system, you'd want to ensure the face is still present and confirmed
",
    "        ret, frame = video_capture.read()
",
    "        if ret:
",
    "            small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)
",
    "            rgb_small_frame = small_frame[:, :, ::-1]
",
    "            face_locations = face_recognition.face_locations(rgb_small_frame)
",
    "            face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)
",
    "
",
    "            if face_encodings:
",
    "                face_distances = face_recognition.face_distance(known_face_encodings, face_encodings[0])
",
    "                best_match_index = np.argmin(face_distances)
",
    "                if face_recognition.compare_faces(known_face_encodings, face_encodings[0])[best_match_index]:
",
    "                    signed_in_user = known_face_names[best_match_index]
",
    "                    status_label.value = f"Status: Signed in as {signed_in_user}!"
",
    "                    with output_widget:
",
    "                        print(f"User {signed_in_user} signed in.")
",
    "                else:
",
    "                    status_label.value = "Status: Unknown face. Cannot sign in."
",
    "            else:
",
    "                status_label.value = "Status: No face detected. Cannot sign in."
",
    "    elif signed_in_user:
",
    "        status_label.value = f"Status: Already signed in as {signed_in_user}."
",
    "    else:
",
    "        status_label.value = "Status: Recognition not running. Start recognition first."
",
    "
",
    "sign_in_button.on_click(on_sign_in_button_clicked)
",
    "
",
    "# Start recognition automatically when the cell is run
",
    "start_recognition()
",
    "
",
    "# To stop the recognition and release webcam, run:
",
    "# stop_recognition()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}